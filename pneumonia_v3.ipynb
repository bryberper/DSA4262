{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"C:/Users/Admin/Downloads/Telegram Desktop/blurred 25.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(zip_path, 'r') as zip:\n",
    "    zip.extractall('folder')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Enable GPU acceleration (if available)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "dataset_path = \"C:/Users/Admin/Downloads/Telegram Desktop/blurred 25\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize images\n",
    "def load_images(path, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    filenames = os.listdir(path)[:1001]  # Limit to 1001 images\n",
    "    for file in filenames:\n",
    "        img = load_img(os.path.join(path, file), target_size=(img_size, img_size), color_mode=\"grayscale\")\n",
    "        img = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load dataset\n",
    "X_train = load_images(dataset_path)\n",
    "print(f\"Loaded {X_train.shape[0]} images with shape {X_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "def augment_images(images):\n",
    "    return next(datagen.flow(images, batch_size=len(images), shuffle=False))\n",
    "\n",
    "# Apply augmentation to dataset\n",
    "X_train = augment_images(X_train)\n",
    "print(\"Augmented images shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = Sequential([\n",
    "        Dense(8 * 8 * 256, activation=\"relu\", input_dim=latent_dim),\n",
    "        Reshape((8, 8, 256)),\n",
    "\n",
    "        Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(1, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")  # Now 128x128x1\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = build_generator(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape=(128, 128, 1)):  # Ensure shape matches your images\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),  # Flatten into a 1D vector\n",
    "        Dense(1, activation=\"sigmoid\")  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    img = generator(gan_input)\n",
    "    validity = discriminator(img)\n",
    "    model = Model(gan_input, validity)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = build_gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 3000\n",
    "BATCH_SIZE = 32\n",
    "SAVE_INTERVAL = 500\n",
    "LATENT_DIM = 100\n",
    "\n",
    "real_labels = np.ones((BATCH_SIZE, 1))\n",
    "fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 1001):  # Reduce epochs if needed\n",
    "    idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\n",
    "    real_images = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, 100))\n",
    "    g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "    if epoch % 100 == 0:  \n",
    "        generator.save(f\"generator_epoch_{epoch}.h5\")\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} | D Loss: {d_loss[0]:.4f} | G Loss: {g_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, n_images=5):\n",
    "    noise = np.random.normal(0, 1, (n_images, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(n_images):\n",
    "        plt.subplot(1, n_images, i + 1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate and display 5 fake X-rays\n",
    "generate_images(generator, 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
